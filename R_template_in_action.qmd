---
title: "R_template in action"
subtitle: "MSL meeting"
author: "Tuomas Eerola"
date: 2023-02-28
highlight-style: arrow
date-format: long
execute:
  echo: true
format: 
  revealjs:
    theme: default
    toc: true
    toc-depth: 1 # default is 3
    toc-title: Contents
    smaller: false
    slide-number: true
    show-slide-number: all
    logo: figures/MusicScienceDU.jpg
    footer: "MSL"
    embed-resources: true
    self-contained: false
    anchor-sections: true
    smooth-scroll: true
---
<!-- renderthis::to_pdf("session1.html") -->

# Preliminaries {background-color="gray"}

```{r}
#| label: load-packages
#| echo: false
library(ggplot2)
library(tidyr)
```

## Preliminaries (1)

This process assumes that you have 

- _RStudio_ installed in your computer (it's free)

- Basic understanding of _RStudio_ workspace, path, and environment (Chapter 6.5 in _Scientific Musicology_) 

- the materials downloaded from [https://github.com/tuomaseerola/R_template](https://github.com/tuomaseerola/R_template) 

  * Tip 1: use the green "Code" button to "Download zip" file

  * Tip 2: extract this into a convenient location on your computer and open `contents.R` with _RStudio_

## Preliminaries (2)

**White slides** refer to the `contents.R` 

**Light blue slides** refer to questions to you

These slides are available at: [https://tuomaseerola.github.io/R_template/report_presentation.html](https://tuomaseerola.github.io/R_template/report_presentation.html)

# Example Data {background-color="gray"}

## Initialise the analysis

We take a raw dataset collected via _Qualtrics_ by Annaliese Micalle-Grimaud that set out to validate her `EmoteControl` system. She collected ratings of multiple expressed emotions for various musical excerpts that she has created and used in a expression production paradigm. This data is _Experiment 2_ of the study (Micallef Grimaud & Eerola, 2022).

```{r}
#| label: initialise
#| echo: true
#| warning: false
#| message: false
## INITIALISE: SET PATH, CLEAR MEMORY & LOAD LIBRARIES
rm(list=ls(all=TRUE))             # Cleans the R memory, just in case
source('scr/load_libraries.R')    # Loads the necessary R libraries
```

## Question: What are packages? (1)

* Why R utilises separate **packages** (libraries in your system)?

* There are 18,419 of these in [CRAN](https://cran.r-project.org)

* Popular ones are
  * `ggplot2`, A grammar of graphics in R
  * `dplyr`, a grammar of data manipulation
  * `tidyr`, a collection of package development tools
  * `foreign`, read data stored by Minitab, S, SAS, SPSS

## Question: What are packages? (2)

To check what you might already have in your _R_, type:
```{r}
#| eval: false
search()
```
If you don't have a library installed, just type

```{r}
#| eval: false
install.packages("ggplot2")
```
After installation, you can load the library for your project with 
```{r}
#| eval: false
library(ggplot2)
```

![Installation vs library (Analogy and image credit to Dianne Cook of Monash University.)](figures/install_vs_library.jpeg)

## Load, preprocess and diagnose

All these operations are sometimes called _data carpentry_.
```{r}
#| label: read-data
## READ data
source('scr/read_data_survey.R')      # Produces data frame v 
head(v,3)
```

## Question: What is the script doing?

This is the only line that matters with `read_data_survey.R`:

```{r}
#| eval: false
v <- read.csv('data/Emotion_Identification_N119_noheader.tsv', header=TRUE, sep = "\t")
```

* note how `folder` and `filename` is specified. Adopt a good filenaming convention for your files. No spaces, and clearly label the status of the data (date or N). 
* see `header`
* separator (if not specified, assumes comma-separation)
* <span style="color:red;">DANGER: file-encoding can be a problem</span> (<span style="color:green;">_UTF-8_ is safe</span>)

## Question: What if the data is in Excel?

If you have the data in an Excel file, you can either 
* convert these into CSV or TSV or 
* utilise `readxl` library and then run:

```{r}
#| eval: false
library(readxl)
v <- read_excel('my_data.xlsx')
```

* `read_excel` has a lot of options (read specific sheets etc.)
* <span style="color:red;">DANGER: Excel files have known deficiencies (date conventions, support for a limited number of columns, version differences, and it is a proprietary format)</span>
  
## Question: What is the structure of the data at this point? {.smaller}

1 What is the size of the data?

2. What variables we have? 

3. What type of variables we have?

4. What do we infer from the column names?

Useful commands: `dim`, `head`, `str`, `is.na`, `View`.

```{r}
#| eval: false
head(v)
```

# Data munging {background-color="gray"}

## Data munging

In the next step this raw data will be munged, that is, pre-processed in several ways. Pre-processing can have multiple steps, here these have broken into two:

1. First operation carries out a long list of renaming the variables (columns in the data, `rename_variables.R`). This can be avoided if the data has these names already, and it is quite useful to try to embed meaningful variables names to the data collection (coding them into the experiment/survey). 
```{r}
#| label: munging
source('munge/rename_variables.R')        # Renames the columns of the v
```

## What happens in this munging? {background-color="lightblue"}

* Can you explain the main changes from the raw data?

Here's an extract of `rename_variables.R`
```{r}
#| eval: false
#### 1. Rename variable headers ---------------------------------------------------
colnames(v)[colnames(v)=="Duration..in.seconds."]<-"Time"
colnames(v)[colnames(v)=="Q3"]<-"Age"
colnames(v)[colnames(v)=="Q4"]<-"Gender"
# .... 

# Note:
# Track rating renamed, where OG = original track and PT = participants' track
# Middle number is number of track, and emotion names at end are the different emotion rating scales
colnames(v)[colnames(v)=="Q14_1"]<-"OG_01_SADNESS"
colnames(v)[colnames(v)=="Q14_2"]<-"OG_01_CALMNESS"
colnames(v)[colnames(v)=="Q14_3"]<-"OG_01_JOY"
```

## Recode instruments (1): Trim unnecessary variables and tidy up

```{r}
#| label: recode
source('munge/recode_instruments.R')      # Produces df (long-form) from v
```

So plenty of things happen in the `recoding_instruments.R`. Let's look inside the script.

## 1. Trim variables

The script will drop all columns mentioned in the `select` command; they are mentioned with negative (-) in from of them, means dropping. 
```{r}
#| eval: false
# eliminating unnecessary columns
v <- dplyr::select(v,-StartDate,-EndDate,-Status,-IPAddress,-Progress,-RecordedDate,-ResponseId,-RecipientLastName,-RecipientFirstName,-RecipientEmail,-ExternalReference,-LocationLatitude,-LocationLongitude,-DistributionChannel,-UserLanguage,-Q1,-Q12_1, -Q12_2, -Q12_3, -Q12_4, -Q12_5, -Q12_6, -Q12_7)
```

## 2. Recode instruments: Add IDs

For convenience, add participant ID's
```{r}
#| eval: false
v$ID <- c(1:length(v$Age)) # Status = dataframe length
v$PID <- paste("S",sprintf("%03d", v$ID),sep="")
v$PID<-factor(v$PID)
ind<-colnames(v)!='ID'
v <- v[, ind]  ## Delete ID and just retain PID
head(v)
```

## 3. Recode instruments: Turn categorical vars into labelled factors

This is done to increase clarity and this will help future analyses as well.
```{r}
#| eval: false
v$Gender <- factor(v$Gender,levels=c(1,2,3),labels = c('Male','Female','Other'))
v$MusicalExpertise <- factor(v$MusicalExpertise,levels = c(1,2,3,4,5,6),
                             labels = c("NonMusician","Music-Loving NonMusician",
                                        "Amateur","Serious Amateur Musician","Semi-Pro","Pro"))
v$MusicalExpertiseBinary<-factor(v$MusicalExpertise,
                                 levels = levels(v$MusicalExpertise),
                                 labels=c('Nonmusician','Nonmusician','Musician','Musician','Musician','Musician'))
```

## 4. Recode instruments: Eliminate incomplete responses

Here we first created a row to identify the NAs (missing values) in the dataset, 
afterwards we created a threshold of 95% completion rate. If participants completed 
more than 95% of the survey, we keep them.

```{r}
#| eval: false
v$NAS <- rowSums(is.na(v[, 11:108]))
NAS <- 100 - (v$NAS/nrow(v))*100
threshold <- 95
good_ones <- NAS >= threshold
v <- v[good_ones, ]
v <- v[,1:110] # drop NAS 
print(paste('Trimmed data: N=',nrow(v)))
head(v)
```

## 5. Recode instruments: Convert into long-format

Pull out emotions and tracks from the data (convert to long-form) and collapse across all 14 tracks. 
```{r}
#| eval: false
df <- pivot_longer(v,cols = 11:108) # These are the columns with ratings
df$Track<-df$name
df$Track <- gsub("[A-Z][A-Z]_", "", df$Track) #function to substitute every "_POWER" with "" in df$variable
df$Track <- gsub("_[A-Z]+$", "", df$Track) #function to substitute every "_POWER" with "" in df$variable

df$Source <- gsub("_[0-9][0-9]_[A-Z]+$", "", df$name) # take out source (OG and PTs ie own vs participant generated)
df$Scale <- gsub("[A-Z][A-Z]_[0-9][0-9]_", "", df$name) # take out scale

df$Track<-factor(df$Track,levels = c('01','02','03','04','05','06','07'),labels = c('Sadness','Joy','Calmness','Anger','Fear','Power','Surprise'))
df$Source<-factor(df$Source,levels = c('OG','PT'),labels = c('Exp1','Exp2'))

colnames(df)[colnames(df)=='value']<-'Rating'
df$Rating <- dplyr::recode(df$Rating, `1` = 1L, `3` = 2L, '4' = 3L, '5' = 4L, '6' = 5L) #  "1" = "1", "3" = "2", "4" = "3", "5"="4", "6" = "5
df$Scale<-factor(df$Scale)
df$PreferredGenre<-factor(df$PreferredGenre)
```

## 6. Recode instruments: Drop unnecessary columns

Finally we have a clean final data frame on long format.
```{r}
#| eval: false
df <- dplyr::select(df,-Country,-Finished,-InstrumentPlayer,-Instrument,-MusicalTraining,-name,-MusicalExpertise,-PreferredGenre)
head(df)
```

## Question: What is the structure of the data at this point?  {background-color="lightblue"}

* Give a short explanation of what do we have now in `df`?

# Descriptives  {background-color="gray"}

## Checking the data: Descriptives

After the munging, it is prudent to check various aspects of the data such as the N, age, and gender ... 

```{r}
#| label: demographics
source('scr/demographics_info.R')     # Reports N, Age and other details
```

## Checking the data: Descriptives

Summaries are easily created with few commands such as `mean`, `sd` or `table` commands:
```{r}
mean(v$Age)
round(mean(v$Age),2)

print(table(v$Gender)) # gender distribution
```

## Question: Can you describe....  {background-color="lightblue"}

* ... how many emotion scales there are in the data?
* ... how many tracks there are in the data?
* ... how many ratings per emotion scales and tracks there are in the data?

tip: table command works here well. You can also combine multiple columns into a table just by referring to multiple `table(df$Source,df$Track)`

## Checking the data (2): Consistency

We can explore the consistency of the ratings across the people. This calculates Cronbach's $\alpha$s reliability coefficient for internal consistency across participants for each concept.

```{r}
#| cache: true
#| df-print: kable
source('scr/interrater_reliability.R')
```

## Checking the data (3): Distributions

We also want to look at the distributions of the collected data in order to learn whether one needs to use certain operations (transformations or resort to non-parametric statistics) in the subsequent analyses (`visualise.R`). This step will also include displaying correlations between the emotion scales which is a useful operation to learn about the overlap of the concepts used in the tasks. 

## Checking the data (3): Distributions

```{r}
#| label: fig-misc
#| fig-width: 8
#| fig-height: 8
source('scr/visualise.R')             # Visualise few aspects of the data
```

## Checking the data (4): Look at the distributions manually

Let's do some basic plotting to look at the distributions.
```{r}
#| label: fig-mpg
#| fig-cap: "Age histogram and distribution across gender."
#| fig-subcap:
#|   - "Age"
#|   - "Age by Gender"
#| layout-ncol: 2
#| column: page
hist(df$Age,col='yellow')
boxplot(Age ~ Gender, data=df,col='pink')
```

# Conclusion {background-color="gray"}

## Conclusion

* We now have mastered the **data carpentry** and **descriptives**
  * reading excel or CSV data into R
  * the data was labelled **badly** in _Qualtrics_, and contained **incomplete data**, which we fixed
  * we converted from *wide-format* to *long-format*
  * we have an explicit **coding of factors** and clear **variable names**
  * All of these operations are saved in scripts, and can be **replicated*; any analysis starts from running these preprocessing scripts on raw data
  * We <U>never</U> manually touch raw data

## Next

The actual inferential analysis (Linear Mixed Models) is next set of operations needed in this project.

_Thanks for Annaliese Micallef-Grimaud for sharing this data. This is Experiment 2 of the study published_: 

* Grimaud, A. M. & Eerola, T. (2022). An Interactive Approach to Emotional Expression through Musical Cues. _Music \& Science, 5_, 1-23. [https://doi.org/10.1177/20592043211061745](https://doi.org/10.1177/20592043211061745)



