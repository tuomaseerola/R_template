---
title: "Reproducible Research"
subtitle: "MSL meeting"
author: "Tuomas Eerola"
date: 2023-02-28
date-format: long
format: 
  revealjs:
    theme: default
    toc: true
    toc-depth: 1 # default is 3
    toc-title: Contents
    smaller: false
    slide-number: true
    show-slide-number: all
    logo: figures/MusicScienceDU.jpg
    footer: "MSL"
    embed-resources: true
    self-contained: false
    bibliography: reproducible.bib
    csl: apa6.cls
    anchor-sections: true
    smooth-scroll: true
---
<!-- renderthis::to_pdf("session1.html") -->

# What is Reproducible Research?

## What is Reproducible Research?

"A study is reproducible if there is a specific set of computational functions/analyses that exactly reproduce all of the numbers and data visualizations in a published paper from raw data. Reproducibility does not require independent data collection and instead uses the methods and data collected by the original investigator." [@marwick2016computational, p. 4]

## Why Reproducible Research?

::: callout-important
Crisis on replication and transparency in empirical research
:::

![](figures/reproducibility_crisis.png)

in _Nature_ [@baker2016]

## Credibility Crisis

- "Why most published research findings are false" [@ioannidis2005most]
- Psychology has lion share of bias/misleading results [@simmons2011] 
- Science: Serious concern about robustness of results
  - 100 studies replicated, about 36% produced statistically significant results [@open2015estimating]


## Credibility Crisis -- Update

"Many Labs 2" Project [@klein2018many]

- $\approx 50\%$ psychology findings replicated
- Small effect sizes
- Consistency across labs
- Alternative explanations controlled for
- Made transparent via [OSF](https://osf.io/8cd4r/) and [Psyarxiv](psyarxiv.com/9654g)

## Many Labs 2 Results

![](figures/manylabs2.png)

## Why <U>Irreproducible</U> Research?

- We don't know better
- We have pressure to publish 
- There is no incentive to produce reproducible research
- Selective reporting drives results (cherry picking, p-hacking, only reporting positive results)
- It keeps us artificially in the business 
  * we are the only ones who have/can process/data/method...
  * "it preserves the competitive edge"

# Benefits of Reproducibility

## Benefits of Reproducibility (1)

### 1. To increase trust

  * Needed in biosciences and social sciences
  * *Pre-registration* of studies from medical sciences

### 2. To comply with the transparency demands

  * Open Access Data is required by all UKRI funding
  * Some journals require transparency (data/analysis, etc.)

![](figures/eKhYvwH.jpg)



## Benefits of Reproducibility (2)

### 3. To collaborate more easily and effectively

- Spot mistakes, encourage learning & exploration 

### 4. To communicate research more clearly

- Workflows that integrate analysis and reporting
- Gain visibility [@piwowar2007sharing]

### 5. To raise awareness of quality concerns

- Journal policies have improved the situation
- Is still neglected in practice [@hardwicke2019]

## Reproducible Research

Article – is just a tip of the iceberg. Reproducible Research makes the whole workflow accessible

<center>![](figures/Iceberg.jpg)</center>

## Types of Reproducibility


  * **Computational reproducibility**: code, software, hardware and implementation details
  
  * **Empirical reproducibility**: information about non-computational empirical scientific experiments & observations
  
  * **Statistical reproducibility**: detailed information is provided about the choice of statistical tests

From @stodden2014implementing. All three can be combined in fully transparent workflows

# Reproducible Music Research?

## Reproducible Music Research?

Attitude towards reproducibility varies across disciplines 

- _MIR_ has led the way ([soundsoftware.ac.uk](http://soundsoftware.ac.uk))

- _Music Psychology_ follows the trajectory: Interest in [replication: special issue in 2013](http://journals.sagepub.com/toc/msxa/17/3), but slow take up

- _Music Intervention research_ (has to register study protocols)

- _Computational music analysis/ethnomusicology_ utilise corpus studies

## How to Achieve Reproducible Research?

Workflows that are reproducible and transparent

-  1. **Design** (sometimes requiring *pre-registration*)
-  2. **Analysis** (using tools that allow reproduction)
-  3. **Data** (data, analysis pipelines, repositories, etc.)
-  4. **Reporting** (linking data, analysis, outputs)

## 1. Designs --  Pre-registration

* The study details (research questions, methods, recruitment, stimuli, analysis details, inferences) are defined and submitted to peer review (_Registered Report_)
  - If a passed, _In-Principle Acceptance_ (IPA)
  - Collect the data, follow the protocol, 2nd peer review 

* Coming to our field (we have pioneered several of these)
  - _Auditory Perception & Cognition_ [@armitage2022]
  - _Music Perception_ [IPA] [@lahdelmaeerola]
  - _Psychonomic Bulletin & Review_ [@eerola_lahdelma2021c]

## Pros and Cons of Pre-registration
  
### [Positives]{style="color: green;"}

- [Improves quality (definitions, design, measures, analysis)]{style="color: green;"}
- [Review conflicts: less at stake without data]{style="color: green;"}
- [Review style: collaborative mode]{style="color: green;"}

### [Negatives]{style="color: red;"}

- [Takes time (additional planning + review)]{style="color: red;"}
- [Reveals study plans to others (but safely so)]{style="color: red;"}
- [**Innovation** is considered more valuable that reliability boost]{style="color: red;"}
  

## 2. Analysis Tools and Reproducibility

* **Music analysis**
  - [Yes: Python (music21, librosa), R (incon, humdrumR)]{style="color: green;"}
  - [No: Sonic Visualiser, sequencers]{style="color: red;"}

* **Statistics**
  - [Yes: R / Jamovi / Python]{style="color: green;"}
  - [No: SPSS]{style="color: red;"}

* **Reporting**
  - [Yes: RMarkdown, Quarto, Jupyter notebooks]{style="color: green;"}
  - [No: Microsoft Word]{style="color: red;"}

## 3. Data Sharing and Analysis Pipeline

- Repositories (Github, OSF, Dataverse, Zenodo, etc.)

![](figures/github_etc_icons.png)

  - [https://github.com/tuomaseerola/opendata](https://github.com/tuomaseerola/opendata)

::: callout-note
Sharing <U>can be done anonymously</U> for review (e.g. https://anonymous.4open.science, drupal.org, OSF)
:::

## 4. Reporting -- Reproducible Workflows (1)

### Experiment Analysis Example

![](figures/workflow2.png)


## 4. Reporting -- Reproducible Workflows (2)

### Corpus Analysis Example

![](figures/workflow.png)



# Ways to Promote Reproducibility

## Ways to Promote Reproducibility

 -  Require reproducibility from PhD students ☑️
 -  Run replication studies in teaching  ☑️
 -  Make it one of your themes in lab meetings ☑️
 -  Steer collaborations into reproducible workflows ☑️

> 	“Reproducibility is like brushing your teeth. It is good for you, but it takes time and effort. Once you learn it, it becomes a habit.” [@baker2016]

## The End {.center}



Slides available at: 

[https://tuomaseerola.github.io/R_template/](https://tuomaseerola.github.io/R_template/)

  see [Summary slides](https://tuomaseerola.github.io/R_template/reproducible_research.html#/title-slide)


## References

::: {#refs}
:::
